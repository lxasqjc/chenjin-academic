---
title: Chen Jin
role: Associate Principal AI Scientist at Centre for Artificial Intelligence (CAI)
avatar_filename: ""
bio: University College London

# interests:
# - Artificial General Intelligence
# - Data and Computation Efficient Machine Learning
# - Computater Vision


social:
  - icon: envelope
    icon_pack: fas
    link: mailto:chen.jin@astrazeneca.com
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.co.uk/citations?hl=en&user=4on9TiAAAAAJ
  - icon: github
    icon_pack: fab
    link: https://github.com/lxasqjc
  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/in/chen-jin-33287593/
  - icon: twitter
    icon_pack: fab
    link: https://twitter.com/Jinchen027
organizations:
  - name: Data Science & Artificial Intelligence, AstraZeneca (UK)
    url: https://www.astrazeneca.com/r-d/data-science-and-ai.html
email: ""
superuser: true
highlight_name: true
---
Hi! My name is Chen Jin, and I’m a research scientist at the Centre for Artificial Intelligence (CAI) at [Data Science & Artificial Intelligence](https://www.astrazeneca.com/r-d/data-science-and-ai.html), AstraZeneca (UK). My research focuses on Large Multimodal Generative Models, Vision-Language Human-Machine Interactions, Computer Vision and Natural Language Processing for Healthcare, and Predictive Models.

**Research focus over time**:
- **UCL (pre-AZ)**: Efficient segmentation of ultra-high-resolution histopathology images, plus early multimodal pretraining work.
- **AstraZeneca 2023**: Diffusion models for image generation (MCPL) and follow-on supervised projects such as Local Diffusion and Segment Anyword, with ongoing causal-adapter and protein-generation extensions under submission.
- **AstraZeneca 2024**: VLM post-training (Lavender) and supervision of LLM inference projects on ensembling and hallucination mitigation (DMoA; Decoding by Contrasting Retrieval Heads).
- **AstraZeneca 2025**: Multimodal LLMs and agentic AI for scientific discovery in medicine, including verifier-guided, test-time scaling multi-agent systems that chain vLLM-served open models with FastAPI-served agents.
- **Looking ahead to 2026**: Continual-learning multi-agent systems with verifier-guided stacks (GEPA, DeepConf, RL) and scalable evaluation infrastructure.

Previously, I was a research assistant at the [Centre for Medical Image Computing (CMIC)](https://www.ucl.ac.uk/medical-image-computing/) at [UCL’s AI Centre](https://www.ucl.ac.uk/ai-centre/), where I worked on Multimodal-Multiscale-Multitask representation learning, image generation and mapping. I have also developed attention-based learnable sampling methods for either [data efficient](https://lxasqjc.github.io/learn-downsample.github.io/) or [computation efficient](https://github.com/lxasqjc/Foveation-Segmentation) machine learning, and applied on segmentation of large volume high-resolution images.

Externally, I got the privilege to collaborate closely with [Dr Ryutaro Tanno](https://rt416.github.io/) from Google DeepMind, [Prof. Daniel Alexander](http://www0.cs.ucl.ac.uk/staff/d.alexander/) from CMIC UCL and [Prof Mihaela van der Schaar](https://www.vanderschaar-lab.com/prof-mihaela-van-der-schaar/) from Artificial Intelligence and Medicine at the University of Cambridge.

I obtained my PhD in Computational Geoscience at the [Institute of GeoEnergy Engineering](https://www.hw.ac.uk/uk/schools/energy-geoscience-infrastructure-society/research/ige.htm/), [Heriot-Watt University](https://www.hw.ac.uk/). My thesis was about developing a Hierarchical Digital Rock Analysis Workflow, involving machine learning-based multi scale-modal image fusion, reconstruction and fluid simulation.

<!-- {{< icon name="download" pack="fas" >}} Download my {{< staticref "uploads/CV_CHEN_JIN_22.pdf" "newtab" >}}CV{{< /staticref >}} (ast updated 14/03/2022). -->

**News**:
- May 2025: We have two papers accepted at ICML 2025: [Diffusion Instruction Tuning](https://astrazeneca.github.io/vlm/) and [Segment Anyword: Mask Prompt Inversion for Open-Set Grounded Segmentation](https://openreview.net/forum?id=9bzgpYtQZn&referrer=%5BTasks%5D(%2Ftasks)).
- Feb 2025: Our latest research [Diffusion Instruction Tuning](https://astrazeneca.github.io/vlm/) is out! Can Stable Diffusion's visual expertise enhance Llama-3.2? We propose Lavender: efficiently fine-tunes advanced vision-language models by aligning their text-vision attention with Stable Diffusion.
- Jan 2025: Our work [Balancing Act: Diversity and Consistency in Large Language Model Ensembles](https://openreview.net/forum?id=Dl6nkKKvlX) is accepted by [ICLR 2025](https://iclr.cc/). We introduce Dynamic Mixture of Agents (DMoA), a novel inference-time ensembling strategy that dynamically adapts to balance performance, diversity, and consistency, achieving state-of-the-art results.
- July 2024: Our work [Local Diffusion](https://arxiv.org/abs/2404.05980) is accepted by [ECCV 2024](https://eccv2024.ecva.net/virtual/2024/papers.html?filter=titles), which explored Tackling Structural Hallucination in Image Translation.
- May 2024: Our work [Multi-Concept Prompt Learning](https://astrazeneca.github.io/mcpl.github.io/) is accepted by [ICML 2024](https://icml.cc/virtual/2024/poster/34548), which explored language-driven concepts learning during human-machine interactions.
- Jan 2022: Our work on [Learning to downsample](https://lxasqjc.github.io/learn-downsample.github.io/) is accepted by [ICLR 2022](https://openreview.net/forum?id=HndgQudNb91), which aiming to adapt the computation/sampling budget to the difficulty of segmented pixel/region.
- July 2021: We are organizing the [foveation project](https://medicss.cs.ucl.ac.uk/projects-2021/#foveation) on [MedICSS Summer School 2021](https://medicss.cs.ucl.ac.uk/programme-2021/).
- Sep 2020: a shorter version of our work on [Foveation for Segmentation](https://chenjin.netlify.app/publication/foveation/) is accepted at MICCAI 2020, also check out [full extensive version](https://arxiv.org/abs/2007.15124v2).
- Aug 2020: Our attempts on [Disentangling human annotation error](https://chenjin.netlify.app/publication/humanerror/) is accepted at NeurIPS 2020.
